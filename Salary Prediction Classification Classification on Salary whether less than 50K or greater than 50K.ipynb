{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RdkqWT2Xfao9",
        "outputId": "41dceb6c-749d-4477-f83c-d1261d45bac3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0af99b5-89ff-401e-8e64-7f4318f3bc42\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0af99b5-89ff-401e-8e64-7f4318f3bc42\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving salary - salary.csv to salary - salary (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load your dataset (example loading from a CSV file)\n",
        "# Replace with your actual data loading method\n",
        "data = pd.read_csv(\"salary - salary.csv\")\n",
        "\n",
        "\n",
        "# Drop rows with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "X = data.drop('salary', axis=1)\n",
        "y = data['salary']\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "column_transformer = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_features),\n",
        "    ('cat', OneHotEncoder(), categorical_features)\n",
        "])\n",
        "\n",
        "X = column_transformer.fit_transform(X)\n",
        "\n",
        "X = X.toarray()\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)  # Adjust learning rate\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=200, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
        "print(f\"Training Loss: {train_loss}\")\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2sXK3XKRe4vr",
        "outputId": "e69cf332-3054-4472-814b-b739f78b44bb"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "105/105 [==============================] - 2s 7ms/step - loss: 0.6851 - accuracy: 0.5787 - val_loss: 0.6606 - val_accuracy: 0.7628\n",
            "Epoch 2/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6278 - accuracy: 0.7051 - val_loss: 0.5601 - val_accuracy: 0.7574\n",
            "Epoch 3/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.7363 - val_loss: 0.4282 - val_accuracy: 0.7852\n",
            "Epoch 4/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4543 - accuracy: 0.7731 - val_loss: 0.3688 - val_accuracy: 0.8326\n",
            "Epoch 5/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.7974 - val_loss: 0.3481 - val_accuracy: 0.8353\n",
            "Epoch 6/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8170 - val_loss: 0.3383 - val_accuracy: 0.8393\n",
            "Epoch 7/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3877 - accuracy: 0.8238 - val_loss: 0.3320 - val_accuracy: 0.8432\n",
            "Epoch 8/300\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8271 - val_loss: 0.3272 - val_accuracy: 0.8443\n",
            "Epoch 9/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8313 - val_loss: 0.3236 - val_accuracy: 0.8470\n",
            "Epoch 10/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3697 - accuracy: 0.8331 - val_loss: 0.3217 - val_accuracy: 0.8486\n",
            "Epoch 11/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3717 - accuracy: 0.8319 - val_loss: 0.3198 - val_accuracy: 0.8480\n",
            "Epoch 12/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3648 - accuracy: 0.8406 - val_loss: 0.3175 - val_accuracy: 0.8486\n",
            "Epoch 13/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3623 - accuracy: 0.8398 - val_loss: 0.3160 - val_accuracy: 0.8499\n",
            "Epoch 14/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3591 - accuracy: 0.8405 - val_loss: 0.3151 - val_accuracy: 0.8524\n",
            "Epoch 15/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3600 - accuracy: 0.8399 - val_loss: 0.3141 - val_accuracy: 0.8522\n",
            "Epoch 16/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8439 - val_loss: 0.3131 - val_accuracy: 0.8518\n",
            "Epoch 17/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8437 - val_loss: 0.3123 - val_accuracy: 0.8516\n",
            "Epoch 18/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3466 - accuracy: 0.8422 - val_loss: 0.3118 - val_accuracy: 0.8522\n",
            "Epoch 19/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3479 - accuracy: 0.8467 - val_loss: 0.3107 - val_accuracy: 0.8518\n",
            "Epoch 20/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.8437 - val_loss: 0.3109 - val_accuracy: 0.8541\n",
            "Epoch 21/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3436 - accuracy: 0.8442 - val_loss: 0.3104 - val_accuracy: 0.8545\n",
            "Epoch 22/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8454 - val_loss: 0.3098 - val_accuracy: 0.8536\n",
            "Epoch 23/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8475 - val_loss: 0.3092 - val_accuracy: 0.8539\n",
            "Epoch 24/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3456 - accuracy: 0.8434 - val_loss: 0.3095 - val_accuracy: 0.8560\n",
            "Epoch 25/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3441 - accuracy: 0.8479 - val_loss: 0.3087 - val_accuracy: 0.8539\n",
            "Epoch 26/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3411 - accuracy: 0.8484 - val_loss: 0.3085 - val_accuracy: 0.8541\n",
            "Epoch 27/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3410 - accuracy: 0.8473 - val_loss: 0.3084 - val_accuracy: 0.8549\n",
            "Epoch 28/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.8498 - val_loss: 0.3079 - val_accuracy: 0.8545\n",
            "Epoch 29/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8507 - val_loss: 0.3079 - val_accuracy: 0.8532\n",
            "Epoch 30/300\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8491 - val_loss: 0.3080 - val_accuracy: 0.8543\n",
            "Epoch 31/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8536 - val_loss: 0.3076 - val_accuracy: 0.8555\n",
            "Epoch 32/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.8479 - val_loss: 0.3075 - val_accuracy: 0.8557\n",
            "Epoch 33/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3336 - accuracy: 0.8460 - val_loss: 0.3077 - val_accuracy: 0.8553\n",
            "Epoch 34/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3339 - accuracy: 0.8464 - val_loss: 0.3075 - val_accuracy: 0.8555\n",
            "Epoch 35/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3297 - accuracy: 0.8496 - val_loss: 0.3072 - val_accuracy: 0.8559\n",
            "Epoch 36/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3346 - accuracy: 0.8487 - val_loss: 0.3070 - val_accuracy: 0.8553\n",
            "Epoch 37/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8490 - val_loss: 0.3068 - val_accuracy: 0.8551\n",
            "Epoch 38/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8510 - val_loss: 0.3070 - val_accuracy: 0.8562\n",
            "Epoch 39/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3327 - accuracy: 0.8503 - val_loss: 0.3069 - val_accuracy: 0.8560\n",
            "Epoch 40/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8511 - val_loss: 0.3072 - val_accuracy: 0.8555\n",
            "Epoch 41/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8500 - val_loss: 0.3071 - val_accuracy: 0.8555\n",
            "Epoch 42/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8508 - val_loss: 0.3064 - val_accuracy: 0.8562\n",
            "Epoch 43/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8525 - val_loss: 0.3071 - val_accuracy: 0.8549\n",
            "Epoch 44/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8501 - val_loss: 0.3065 - val_accuracy: 0.8572\n",
            "Epoch 45/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8506 - val_loss: 0.3065 - val_accuracy: 0.8566\n",
            "Epoch 46/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3291 - accuracy: 0.8508 - val_loss: 0.3061 - val_accuracy: 0.8566\n",
            "Epoch 47/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8520 - val_loss: 0.3064 - val_accuracy: 0.8557\n",
            "Epoch 48/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.8512 - val_loss: 0.3065 - val_accuracy: 0.8562\n",
            "Epoch 49/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8528 - val_loss: 0.3059 - val_accuracy: 0.8572\n",
            "Epoch 50/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3281 - accuracy: 0.8527 - val_loss: 0.3064 - val_accuracy: 0.8557\n",
            "Epoch 51/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3304 - accuracy: 0.8532 - val_loss: 0.3058 - val_accuracy: 0.8549\n",
            "Epoch 52/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.8526 - val_loss: 0.3059 - val_accuracy: 0.8555\n",
            "Epoch 53/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3256 - accuracy: 0.8538 - val_loss: 0.3061 - val_accuracy: 0.8562\n",
            "Epoch 54/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3250 - accuracy: 0.8532 - val_loss: 0.3068 - val_accuracy: 0.8547\n",
            "Epoch 55/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3280 - accuracy: 0.8523 - val_loss: 0.3061 - val_accuracy: 0.8547\n",
            "Epoch 56/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3243 - accuracy: 0.8542 - val_loss: 0.3063 - val_accuracy: 0.8547\n",
            "Epoch 57/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3229 - accuracy: 0.8546 - val_loss: 0.3057 - val_accuracy: 0.8553\n",
            "Epoch 58/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8537 - val_loss: 0.3058 - val_accuracy: 0.8559\n",
            "Epoch 59/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8528 - val_loss: 0.3053 - val_accuracy: 0.8551\n",
            "Epoch 60/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8519 - val_loss: 0.3058 - val_accuracy: 0.8541\n",
            "Epoch 61/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8538 - val_loss: 0.3065 - val_accuracy: 0.8539\n",
            "Epoch 62/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3225 - accuracy: 0.8554 - val_loss: 0.3058 - val_accuracy: 0.8549\n",
            "Epoch 63/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8570 - val_loss: 0.3056 - val_accuracy: 0.8549\n",
            "Epoch 64/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.8536 - val_loss: 0.3061 - val_accuracy: 0.8539\n",
            "Epoch 65/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8558 - val_loss: 0.3058 - val_accuracy: 0.8541\n",
            "Epoch 66/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3200 - accuracy: 0.8563 - val_loss: 0.3054 - val_accuracy: 0.8555\n",
            "Epoch 67/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3181 - accuracy: 0.8569 - val_loss: 0.3056 - val_accuracy: 0.8551\n",
            "Epoch 68/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3226 - accuracy: 0.8531 - val_loss: 0.3052 - val_accuracy: 0.8557\n",
            "Epoch 69/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3234 - accuracy: 0.8569 - val_loss: 0.3051 - val_accuracy: 0.8551\n",
            "Epoch 70/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3195 - accuracy: 0.8572 - val_loss: 0.3058 - val_accuracy: 0.8537\n",
            "Epoch 71/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.8583 - val_loss: 0.3046 - val_accuracy: 0.8555\n",
            "Epoch 72/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3171 - accuracy: 0.8572 - val_loss: 0.3049 - val_accuracy: 0.8549\n",
            "Epoch 73/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3200 - accuracy: 0.8576 - val_loss: 0.3053 - val_accuracy: 0.8545\n",
            "Epoch 74/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3200 - accuracy: 0.8566 - val_loss: 0.3049 - val_accuracy: 0.8551\n",
            "Epoch 75/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.8586 - val_loss: 0.3057 - val_accuracy: 0.8543\n",
            "Epoch 76/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3163 - accuracy: 0.8582 - val_loss: 0.3057 - val_accuracy: 0.8545\n",
            "Epoch 77/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3201 - accuracy: 0.8562 - val_loss: 0.3058 - val_accuracy: 0.8541\n",
            "Epoch 78/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3174 - accuracy: 0.8603 - val_loss: 0.3051 - val_accuracy: 0.8541\n",
            "Epoch 79/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3150 - accuracy: 0.8568 - val_loss: 0.3056 - val_accuracy: 0.8545\n",
            "Epoch 80/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3178 - accuracy: 0.8581 - val_loss: 0.3052 - val_accuracy: 0.8536\n",
            "Epoch 81/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3164 - accuracy: 0.8570 - val_loss: 0.3055 - val_accuracy: 0.8532\n",
            "Epoch 82/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3186 - accuracy: 0.8579 - val_loss: 0.3050 - val_accuracy: 0.8532\n",
            "Epoch 83/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3172 - accuracy: 0.8575 - val_loss: 0.3049 - val_accuracy: 0.8553\n",
            "Epoch 84/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3151 - accuracy: 0.8575 - val_loss: 0.3050 - val_accuracy: 0.8543\n",
            "Epoch 85/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.8583 - val_loss: 0.3043 - val_accuracy: 0.8551\n",
            "Epoch 86/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3172 - accuracy: 0.8563 - val_loss: 0.3052 - val_accuracy: 0.8549\n",
            "Epoch 87/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3178 - accuracy: 0.8566 - val_loss: 0.3052 - val_accuracy: 0.8555\n",
            "Epoch 88/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8603 - val_loss: 0.3054 - val_accuracy: 0.8547\n",
            "Epoch 89/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3179 - accuracy: 0.8573 - val_loss: 0.3052 - val_accuracy: 0.8543\n",
            "Epoch 90/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3135 - accuracy: 0.8609 - val_loss: 0.3051 - val_accuracy: 0.8545\n",
            "Epoch 91/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3158 - accuracy: 0.8592 - val_loss: 0.3048 - val_accuracy: 0.8559\n",
            "Epoch 92/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3128 - accuracy: 0.8590 - val_loss: 0.3046 - val_accuracy: 0.8555\n",
            "Epoch 93/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3108 - accuracy: 0.8611 - val_loss: 0.3050 - val_accuracy: 0.8551\n",
            "Epoch 94/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3150 - accuracy: 0.8606 - val_loss: 0.3057 - val_accuracy: 0.8553\n",
            "Epoch 95/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3123 - accuracy: 0.8582 - val_loss: 0.3060 - val_accuracy: 0.8541\n",
            "Epoch 96/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8589 - val_loss: 0.3051 - val_accuracy: 0.8555\n",
            "Epoch 97/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8616 - val_loss: 0.3053 - val_accuracy: 0.8553\n",
            "Epoch 98/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3150 - accuracy: 0.8583 - val_loss: 0.3050 - val_accuracy: 0.8553\n",
            "Epoch 99/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3125 - accuracy: 0.8581 - val_loss: 0.3057 - val_accuracy: 0.8537\n",
            "Epoch 100/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3126 - accuracy: 0.8608 - val_loss: 0.3045 - val_accuracy: 0.8564\n",
            "Epoch 101/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3116 - accuracy: 0.8581 - val_loss: 0.3055 - val_accuracy: 0.8545\n",
            "Epoch 102/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.8592 - val_loss: 0.3049 - val_accuracy: 0.8576\n",
            "Epoch 103/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8616 - val_loss: 0.3052 - val_accuracy: 0.8545\n",
            "Epoch 104/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3133 - accuracy: 0.8609 - val_loss: 0.3051 - val_accuracy: 0.8574\n",
            "Epoch 105/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3108 - accuracy: 0.8611 - val_loss: 0.3052 - val_accuracy: 0.8560\n",
            "Epoch 106/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3090 - accuracy: 0.8612 - val_loss: 0.3055 - val_accuracy: 0.8553\n",
            "Epoch 107/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3124 - accuracy: 0.8604 - val_loss: 0.3065 - val_accuracy: 0.8549\n",
            "Epoch 108/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8594 - val_loss: 0.3045 - val_accuracy: 0.8566\n",
            "Epoch 109/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8620 - val_loss: 0.3050 - val_accuracy: 0.8568\n",
            "Epoch 110/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3105 - accuracy: 0.8627 - val_loss: 0.3050 - val_accuracy: 0.8576\n",
            "Epoch 111/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3107 - accuracy: 0.8632 - val_loss: 0.3053 - val_accuracy: 0.8551\n",
            "Epoch 112/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3084 - accuracy: 0.8627 - val_loss: 0.3051 - val_accuracy: 0.8560\n",
            "Epoch 113/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8604 - val_loss: 0.3052 - val_accuracy: 0.8559\n",
            "Epoch 114/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8637 - val_loss: 0.3051 - val_accuracy: 0.8566\n",
            "Epoch 115/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.8597 - val_loss: 0.3052 - val_accuracy: 0.8560\n",
            "Epoch 116/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8603 - val_loss: 0.3046 - val_accuracy: 0.8557\n",
            "Epoch 117/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8616 - val_loss: 0.3052 - val_accuracy: 0.8555\n",
            "Epoch 118/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3092 - accuracy: 0.8611 - val_loss: 0.3057 - val_accuracy: 0.8539\n",
            "Epoch 119/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3071 - accuracy: 0.8599 - val_loss: 0.3052 - val_accuracy: 0.8557\n",
            "Epoch 120/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3068 - accuracy: 0.8617 - val_loss: 0.3057 - val_accuracy: 0.8566\n",
            "Epoch 121/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3094 - accuracy: 0.8609 - val_loss: 0.3053 - val_accuracy: 0.8549\n",
            "Epoch 122/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3064 - accuracy: 0.8626 - val_loss: 0.3054 - val_accuracy: 0.8549\n",
            "Epoch 123/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3073 - accuracy: 0.8610 - val_loss: 0.3053 - val_accuracy: 0.8543\n",
            "Epoch 124/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3074 - accuracy: 0.8624 - val_loss: 0.3046 - val_accuracy: 0.8553\n",
            "Epoch 125/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.8622 - val_loss: 0.3060 - val_accuracy: 0.8543\n",
            "Epoch 126/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3069 - accuracy: 0.8633 - val_loss: 0.3060 - val_accuracy: 0.8541\n",
            "Epoch 127/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8596 - val_loss: 0.3056 - val_accuracy: 0.8541\n",
            "Epoch 128/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3080 - accuracy: 0.8628 - val_loss: 0.3055 - val_accuracy: 0.8547\n",
            "Epoch 129/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8618 - val_loss: 0.3060 - val_accuracy: 0.8545\n",
            "Epoch 130/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3046 - accuracy: 0.8625 - val_loss: 0.3058 - val_accuracy: 0.8559\n",
            "Epoch 131/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8636 - val_loss: 0.3058 - val_accuracy: 0.8559\n",
            "Epoch 132/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3052 - accuracy: 0.8633 - val_loss: 0.3057 - val_accuracy: 0.8557\n",
            "Epoch 133/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.8641 - val_loss: 0.3060 - val_accuracy: 0.8555\n",
            "Epoch 134/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3066 - accuracy: 0.8627 - val_loss: 0.3054 - val_accuracy: 0.8553\n",
            "Epoch 135/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.8616 - val_loss: 0.3060 - val_accuracy: 0.8547\n",
            "Epoch 136/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3050 - accuracy: 0.8637 - val_loss: 0.3053 - val_accuracy: 0.8553\n",
            "Epoch 137/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3043 - accuracy: 0.8625 - val_loss: 0.3059 - val_accuracy: 0.8551\n",
            "Epoch 138/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3033 - accuracy: 0.8643 - val_loss: 0.3059 - val_accuracy: 0.8559\n",
            "Epoch 139/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3054 - accuracy: 0.8637 - val_loss: 0.3064 - val_accuracy: 0.8551\n",
            "Epoch 140/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8637 - val_loss: 0.3067 - val_accuracy: 0.8551\n",
            "Epoch 141/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3031 - accuracy: 0.8628 - val_loss: 0.3070 - val_accuracy: 0.8555\n",
            "Epoch 142/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3014 - accuracy: 0.8655 - val_loss: 0.3071 - val_accuracy: 0.8562\n",
            "Epoch 143/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.3031 - accuracy: 0.8644 - val_loss: 0.3072 - val_accuracy: 0.8560\n",
            "Epoch 144/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.3040 - accuracy: 0.8649 - val_loss: 0.3081 - val_accuracy: 0.8547\n",
            "Epoch 145/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3008 - accuracy: 0.8641 - val_loss: 0.3080 - val_accuracy: 0.8559\n",
            "Epoch 146/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.8625 - val_loss: 0.3077 - val_accuracy: 0.8568\n",
            "Epoch 147/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3017 - accuracy: 0.8640 - val_loss: 0.3070 - val_accuracy: 0.8559\n",
            "Epoch 148/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3033 - accuracy: 0.8662 - val_loss: 0.3069 - val_accuracy: 0.8566\n",
            "Epoch 149/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.8641 - val_loss: 0.3067 - val_accuracy: 0.8562\n",
            "Epoch 150/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8640 - val_loss: 0.3068 - val_accuracy: 0.8564\n",
            "Epoch 151/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3021 - accuracy: 0.8626 - val_loss: 0.3063 - val_accuracy: 0.8572\n",
            "Epoch 152/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8655 - val_loss: 0.3067 - val_accuracy: 0.8557\n",
            "Epoch 153/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3024 - accuracy: 0.8646 - val_loss: 0.3064 - val_accuracy: 0.8559\n",
            "Epoch 154/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.8652 - val_loss: 0.3075 - val_accuracy: 0.8564\n",
            "Epoch 155/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3002 - accuracy: 0.8644 - val_loss: 0.3074 - val_accuracy: 0.8560\n",
            "Epoch 156/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3025 - accuracy: 0.8656 - val_loss: 0.3073 - val_accuracy: 0.8574\n",
            "Epoch 157/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8643 - val_loss: 0.3063 - val_accuracy: 0.8576\n",
            "Epoch 158/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3008 - accuracy: 0.8656 - val_loss: 0.3067 - val_accuracy: 0.8560\n",
            "Epoch 159/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.8647 - val_loss: 0.3080 - val_accuracy: 0.8570\n",
            "Epoch 160/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.8654 - val_loss: 0.3071 - val_accuracy: 0.8570\n",
            "Epoch 161/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3005 - accuracy: 0.8662 - val_loss: 0.3071 - val_accuracy: 0.8570\n",
            "Epoch 162/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2992 - accuracy: 0.8647 - val_loss: 0.3071 - val_accuracy: 0.8568\n",
            "Epoch 163/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2997 - accuracy: 0.8647 - val_loss: 0.3086 - val_accuracy: 0.8570\n",
            "Epoch 164/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2983 - accuracy: 0.8671 - val_loss: 0.3074 - val_accuracy: 0.8578\n",
            "Epoch 165/300\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3004 - accuracy: 0.8668 - val_loss: 0.3071 - val_accuracy: 0.8582\n",
            "Epoch 166/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.8655 - val_loss: 0.3078 - val_accuracy: 0.8589\n",
            "Epoch 167/300\n",
            "105/105 [==============================] - 2s 15ms/step - loss: 0.2994 - accuracy: 0.8673 - val_loss: 0.3082 - val_accuracy: 0.8570\n",
            "Epoch 168/300\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2981 - accuracy: 0.8677 - val_loss: 0.3087 - val_accuracy: 0.8566\n",
            "Epoch 169/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3018 - accuracy: 0.8636 - val_loss: 0.3072 - val_accuracy: 0.8568\n",
            "Epoch 170/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2975 - accuracy: 0.8644 - val_loss: 0.3080 - val_accuracy: 0.8572\n",
            "Epoch 171/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8628 - val_loss: 0.3071 - val_accuracy: 0.8570\n",
            "Epoch 172/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2969 - accuracy: 0.8670 - val_loss: 0.3101 - val_accuracy: 0.8574\n",
            "Epoch 173/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2972 - accuracy: 0.8648 - val_loss: 0.3085 - val_accuracy: 0.8574\n",
            "Epoch 174/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.8638 - val_loss: 0.3089 - val_accuracy: 0.8566\n",
            "Epoch 175/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.8674 - val_loss: 0.3080 - val_accuracy: 0.8583\n",
            "Epoch 176/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2967 - accuracy: 0.8658 - val_loss: 0.3081 - val_accuracy: 0.8570\n",
            "Epoch 177/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2997 - accuracy: 0.8642 - val_loss: 0.3085 - val_accuracy: 0.8576\n",
            "Epoch 178/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3007 - accuracy: 0.8635 - val_loss: 0.3080 - val_accuracy: 0.8580\n",
            "Epoch 179/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2962 - accuracy: 0.8648 - val_loss: 0.3079 - val_accuracy: 0.8572\n",
            "Epoch 180/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2964 - accuracy: 0.8686 - val_loss: 0.3083 - val_accuracy: 0.8562\n",
            "Epoch 181/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2948 - accuracy: 0.8668 - val_loss: 0.3097 - val_accuracy: 0.8564\n",
            "Epoch 182/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2974 - accuracy: 0.8667 - val_loss: 0.3089 - val_accuracy: 0.8568\n",
            "Epoch 183/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2939 - accuracy: 0.8657 - val_loss: 0.3096 - val_accuracy: 0.8562\n",
            "Epoch 184/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8660 - val_loss: 0.3100 - val_accuracy: 0.8566\n",
            "Epoch 185/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2944 - accuracy: 0.8659 - val_loss: 0.3088 - val_accuracy: 0.8560\n",
            "Epoch 186/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2971 - accuracy: 0.8664 - val_loss: 0.3084 - val_accuracy: 0.8566\n",
            "Epoch 187/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2953 - accuracy: 0.8661 - val_loss: 0.3093 - val_accuracy: 0.8564\n",
            "Epoch 188/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2950 - accuracy: 0.8665 - val_loss: 0.3099 - val_accuracy: 0.8572\n",
            "Epoch 189/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2946 - accuracy: 0.8681 - val_loss: 0.3097 - val_accuracy: 0.8570\n",
            "Epoch 190/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2966 - accuracy: 0.8666 - val_loss: 0.3101 - val_accuracy: 0.8562\n",
            "Epoch 191/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2950 - accuracy: 0.8663 - val_loss: 0.3107 - val_accuracy: 0.8580\n",
            "Epoch 192/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.8684 - val_loss: 0.3094 - val_accuracy: 0.8570\n",
            "Epoch 193/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2952 - accuracy: 0.8675 - val_loss: 0.3096 - val_accuracy: 0.8578\n",
            "Epoch 194/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2923 - accuracy: 0.8680 - val_loss: 0.3115 - val_accuracy: 0.8574\n",
            "Epoch 195/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8658 - val_loss: 0.3102 - val_accuracy: 0.8580\n",
            "Epoch 196/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8664 - val_loss: 0.3100 - val_accuracy: 0.8560\n",
            "Epoch 197/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2936 - accuracy: 0.8675 - val_loss: 0.3098 - val_accuracy: 0.8568\n",
            "Epoch 198/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.8656 - val_loss: 0.3101 - val_accuracy: 0.8564\n",
            "Epoch 199/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2928 - accuracy: 0.8683 - val_loss: 0.3109 - val_accuracy: 0.8570\n",
            "Epoch 200/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2928 - accuracy: 0.8669 - val_loss: 0.3108 - val_accuracy: 0.8566\n",
            "Epoch 201/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2940 - accuracy: 0.8673 - val_loss: 0.3106 - val_accuracy: 0.8578\n",
            "Epoch 202/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2912 - accuracy: 0.8672 - val_loss: 0.3106 - val_accuracy: 0.8564\n",
            "Epoch 203/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2920 - accuracy: 0.8673 - val_loss: 0.3115 - val_accuracy: 0.8574\n",
            "Epoch 204/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2952 - accuracy: 0.8685 - val_loss: 0.3112 - val_accuracy: 0.8560\n",
            "Epoch 205/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2954 - accuracy: 0.8675 - val_loss: 0.3110 - val_accuracy: 0.8562\n",
            "Epoch 206/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2951 - accuracy: 0.8647 - val_loss: 0.3098 - val_accuracy: 0.8574\n",
            "Epoch 207/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2940 - accuracy: 0.8675 - val_loss: 0.3101 - val_accuracy: 0.8557\n",
            "Epoch 208/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2915 - accuracy: 0.8696 - val_loss: 0.3107 - val_accuracy: 0.8564\n",
            "Epoch 209/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.8675 - val_loss: 0.3104 - val_accuracy: 0.8576\n",
            "Epoch 210/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2913 - accuracy: 0.8653 - val_loss: 0.3113 - val_accuracy: 0.8574\n",
            "Epoch 211/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2904 - accuracy: 0.8686 - val_loss: 0.3118 - val_accuracy: 0.8570\n",
            "Epoch 212/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2913 - accuracy: 0.8658 - val_loss: 0.3110 - val_accuracy: 0.8568\n",
            "Epoch 213/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2899 - accuracy: 0.8690 - val_loss: 0.3121 - val_accuracy: 0.8568\n",
            "Epoch 214/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2920 - accuracy: 0.8687 - val_loss: 0.3120 - val_accuracy: 0.8568\n",
            "Epoch 215/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2910 - accuracy: 0.8676 - val_loss: 0.3129 - val_accuracy: 0.8564\n",
            "Epoch 216/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2888 - accuracy: 0.8680 - val_loss: 0.3121 - val_accuracy: 0.8566\n",
            "Epoch 217/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2908 - accuracy: 0.8659 - val_loss: 0.3133 - val_accuracy: 0.8566\n",
            "Epoch 218/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2895 - accuracy: 0.8692 - val_loss: 0.3122 - val_accuracy: 0.8576\n",
            "Epoch 219/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2886 - accuracy: 0.8687 - val_loss: 0.3123 - val_accuracy: 0.8566\n",
            "Epoch 220/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2921 - accuracy: 0.8658 - val_loss: 0.3139 - val_accuracy: 0.8572\n",
            "Epoch 221/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2898 - accuracy: 0.8676 - val_loss: 0.3138 - val_accuracy: 0.8572\n",
            "Epoch 222/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.8671 - val_loss: 0.3130 - val_accuracy: 0.8568\n",
            "Epoch 223/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2901 - accuracy: 0.8670 - val_loss: 0.3134 - val_accuracy: 0.8570\n",
            "Epoch 224/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2899 - accuracy: 0.8683 - val_loss: 0.3126 - val_accuracy: 0.8564\n",
            "Epoch 225/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.8696 - val_loss: 0.3142 - val_accuracy: 0.8559\n",
            "Epoch 226/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2894 - accuracy: 0.8663 - val_loss: 0.3126 - val_accuracy: 0.8578\n",
            "Epoch 227/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2912 - accuracy: 0.8679 - val_loss: 0.3126 - val_accuracy: 0.8572\n",
            "Epoch 228/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2882 - accuracy: 0.8676 - val_loss: 0.3129 - val_accuracy: 0.8572\n",
            "Epoch 229/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2884 - accuracy: 0.8682 - val_loss: 0.3136 - val_accuracy: 0.8583\n",
            "Epoch 230/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2875 - accuracy: 0.8687 - val_loss: 0.3152 - val_accuracy: 0.8585\n",
            "Epoch 231/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.8677 - val_loss: 0.3127 - val_accuracy: 0.8585\n",
            "Epoch 232/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2874 - accuracy: 0.8676 - val_loss: 0.3135 - val_accuracy: 0.8578\n",
            "Epoch 233/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2886 - accuracy: 0.8680 - val_loss: 0.3131 - val_accuracy: 0.8589\n",
            "Epoch 234/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2849 - accuracy: 0.8722 - val_loss: 0.3153 - val_accuracy: 0.8587\n",
            "Epoch 235/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.8685 - val_loss: 0.3138 - val_accuracy: 0.8576\n",
            "Epoch 236/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2856 - accuracy: 0.8673 - val_loss: 0.3145 - val_accuracy: 0.8589\n",
            "Epoch 237/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8708 - val_loss: 0.3147 - val_accuracy: 0.8576\n",
            "Epoch 238/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2866 - accuracy: 0.8702 - val_loss: 0.3145 - val_accuracy: 0.8591\n",
            "Epoch 239/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2873 - accuracy: 0.8675 - val_loss: 0.3157 - val_accuracy: 0.8580\n",
            "Epoch 240/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2855 - accuracy: 0.8700 - val_loss: 0.3153 - val_accuracy: 0.8572\n",
            "Epoch 241/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2866 - accuracy: 0.8703 - val_loss: 0.3151 - val_accuracy: 0.8578\n",
            "Epoch 242/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.8698 - val_loss: 0.3153 - val_accuracy: 0.8568\n",
            "Epoch 243/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.8697 - val_loss: 0.3144 - val_accuracy: 0.8582\n",
            "Epoch 244/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2866 - accuracy: 0.8690 - val_loss: 0.3161 - val_accuracy: 0.8568\n",
            "Epoch 245/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2866 - accuracy: 0.8675 - val_loss: 0.3172 - val_accuracy: 0.8568\n",
            "Epoch 246/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2854 - accuracy: 0.8670 - val_loss: 0.3172 - val_accuracy: 0.8568\n",
            "Epoch 247/300\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2832 - accuracy: 0.8690 - val_loss: 0.3168 - val_accuracy: 0.8585\n",
            "Epoch 248/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2847 - accuracy: 0.8674 - val_loss: 0.3190 - val_accuracy: 0.8566\n",
            "Epoch 249/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2859 - accuracy: 0.8698 - val_loss: 0.3169 - val_accuracy: 0.8570\n",
            "Epoch 250/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2838 - accuracy: 0.8708 - val_loss: 0.3184 - val_accuracy: 0.8572\n",
            "Epoch 251/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2855 - accuracy: 0.8685 - val_loss: 0.3180 - val_accuracy: 0.8572\n",
            "Epoch 252/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2855 - accuracy: 0.8705 - val_loss: 0.3174 - val_accuracy: 0.8576\n",
            "Epoch 253/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2845 - accuracy: 0.8697 - val_loss: 0.3182 - val_accuracy: 0.8574\n",
            "Epoch 254/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.8676 - val_loss: 0.3183 - val_accuracy: 0.8578\n",
            "Epoch 255/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2851 - accuracy: 0.8701 - val_loss: 0.3171 - val_accuracy: 0.8574\n",
            "Epoch 256/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2860 - accuracy: 0.8696 - val_loss: 0.3190 - val_accuracy: 0.8578\n",
            "Epoch 257/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2830 - accuracy: 0.8688 - val_loss: 0.3186 - val_accuracy: 0.8583\n",
            "Epoch 258/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2845 - accuracy: 0.8696 - val_loss: 0.3181 - val_accuracy: 0.8570\n",
            "Epoch 259/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2878 - accuracy: 0.8693 - val_loss: 0.3173 - val_accuracy: 0.8587\n",
            "Epoch 260/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.8697 - val_loss: 0.3176 - val_accuracy: 0.8560\n",
            "Epoch 261/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.8694 - val_loss: 0.3188 - val_accuracy: 0.8572\n",
            "Epoch 262/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2844 - accuracy: 0.8716 - val_loss: 0.3186 - val_accuracy: 0.8591\n",
            "Epoch 263/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2838 - accuracy: 0.8705 - val_loss: 0.3181 - val_accuracy: 0.8578\n",
            "Epoch 264/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2855 - accuracy: 0.8713 - val_loss: 0.3200 - val_accuracy: 0.8578\n",
            "Epoch 265/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2819 - accuracy: 0.8701 - val_loss: 0.3193 - val_accuracy: 0.8582\n",
            "Epoch 266/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2861 - accuracy: 0.8682 - val_loss: 0.3192 - val_accuracy: 0.8564\n",
            "Epoch 267/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2850 - accuracy: 0.8712 - val_loss: 0.3178 - val_accuracy: 0.8578\n",
            "Epoch 268/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8707 - val_loss: 0.3204 - val_accuracy: 0.8566\n",
            "Epoch 269/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.8682 - val_loss: 0.3215 - val_accuracy: 0.8560\n",
            "Epoch 270/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2825 - accuracy: 0.8713 - val_loss: 0.3211 - val_accuracy: 0.8564\n",
            "Epoch 271/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2820 - accuracy: 0.8709 - val_loss: 0.3181 - val_accuracy: 0.8570\n",
            "Epoch 272/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2825 - accuracy: 0.8705 - val_loss: 0.3209 - val_accuracy: 0.8582\n",
            "Epoch 273/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2817 - accuracy: 0.8699 - val_loss: 0.3195 - val_accuracy: 0.8583\n",
            "Epoch 274/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2836 - accuracy: 0.8698 - val_loss: 0.3203 - val_accuracy: 0.8574\n",
            "Epoch 275/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2835 - accuracy: 0.8688 - val_loss: 0.3224 - val_accuracy: 0.8578\n",
            "Epoch 276/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2785 - accuracy: 0.8737 - val_loss: 0.3257 - val_accuracy: 0.8582\n",
            "Epoch 277/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2807 - accuracy: 0.8710 - val_loss: 0.3221 - val_accuracy: 0.8568\n",
            "Epoch 278/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2821 - accuracy: 0.8693 - val_loss: 0.3211 - val_accuracy: 0.8564\n",
            "Epoch 279/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2839 - accuracy: 0.8702 - val_loss: 0.3190 - val_accuracy: 0.8572\n",
            "Epoch 280/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2805 - accuracy: 0.8722 - val_loss: 0.3258 - val_accuracy: 0.8559\n",
            "Epoch 281/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2793 - accuracy: 0.8722 - val_loss: 0.3231 - val_accuracy: 0.8566\n",
            "Epoch 282/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2783 - accuracy: 0.8728 - val_loss: 0.3238 - val_accuracy: 0.8564\n",
            "Epoch 283/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8723 - val_loss: 0.3217 - val_accuracy: 0.8576\n",
            "Epoch 284/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2839 - accuracy: 0.8733 - val_loss: 0.3221 - val_accuracy: 0.8576\n",
            "Epoch 285/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2791 - accuracy: 0.8733 - val_loss: 0.3220 - val_accuracy: 0.8572\n",
            "Epoch 286/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2807 - accuracy: 0.8705 - val_loss: 0.3236 - val_accuracy: 0.8566\n",
            "Epoch 287/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2795 - accuracy: 0.8717 - val_loss: 0.3238 - val_accuracy: 0.8574\n",
            "Epoch 288/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2775 - accuracy: 0.8710 - val_loss: 0.3210 - val_accuracy: 0.8578\n",
            "Epoch 289/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2799 - accuracy: 0.8735 - val_loss: 0.3221 - val_accuracy: 0.8585\n",
            "Epoch 290/300\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.2768 - accuracy: 0.8735 - val_loss: 0.3219 - val_accuracy: 0.8566\n",
            "Epoch 291/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2769 - accuracy: 0.8710 - val_loss: 0.3251 - val_accuracy: 0.8560\n",
            "Epoch 292/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2786 - accuracy: 0.8713 - val_loss: 0.3241 - val_accuracy: 0.8568\n",
            "Epoch 293/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2801 - accuracy: 0.8707 - val_loss: 0.3234 - val_accuracy: 0.8572\n",
            "Epoch 294/300\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.2794 - accuracy: 0.8693 - val_loss: 0.3252 - val_accuracy: 0.8568\n",
            "Epoch 295/300\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.2787 - accuracy: 0.8723 - val_loss: 0.3238 - val_accuracy: 0.8574\n",
            "Epoch 296/300\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.2777 - accuracy: 0.8724 - val_loss: 0.3241 - val_accuracy: 0.8574\n",
            "Epoch 297/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2785 - accuracy: 0.8726 - val_loss: 0.3238 - val_accuracy: 0.8570\n",
            "Epoch 298/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2810 - accuracy: 0.8709 - val_loss: 0.3241 - val_accuracy: 0.8568\n",
            "Epoch 299/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2765 - accuracy: 0.8737 - val_loss: 0.3255 - val_accuracy: 0.8580\n",
            "Epoch 300/300\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.2786 - accuracy: 0.8728 - val_loss: 0.3256 - val_accuracy: 0.8572\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8612\n",
            "Test Loss: 0.32428136467933655\n",
            "Test Accuracy: 0.8612006902694702\n",
            "814/814 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.8762\n",
            "Training Loss: 0.2621072232723236\n",
            "Training Accuracy: 0.8761901259422302\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}